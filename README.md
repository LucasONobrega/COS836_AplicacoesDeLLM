# Handling Large Contexts in Large Language Models: Strategies Beyond Model Limits

This repository contains all the files used in the course Aplicações de LLM (COS836) of the Programa de Engenharia de Sistemas e Computação (COPPE/PESC) at Universidade Federal do Rio de Janeiro (UFRJ).

**Abstract**

Within the domain of Large Language Models (LLMs) like GPT, and LLaMA, context size limitations pose significant challenges, especially when the text corpus surpasses the model's maximum input size. This paper presents a review, subsequently introducing heuristics, techniques, and algorithms tailored for processing large contexts. Drawing inspiration from parallel models and functional programming operations, we propose a bifurcated solution: text partitioning and its subsequent utilization.
